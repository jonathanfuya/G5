{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "whole-timber",
   "metadata": {},
   "source": [
    "# Covid-19\n",
    "Utilizar Spark para cargar los dataset de del reposirotio: \n",
    "    https://www.kaggle.com/datasets/imdevskp/corona-virus-report "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-czech",
   "metadata": {},
   "source": [
    "## Cargar información utilizando RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "polar-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas de PySpark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType,DateType\n",
    "from pyspark.sql.functions import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alike-account",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una instancia de SparkContext y SparkSession\n",
    "sc = SparkContext(\"local\", \"CSV to Parquet\")\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-light",
   "metadata": {},
   "source": [
    "### Función para convertir un archivo CSV en un DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cordless-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para convertir un archivo CSV en un DataFrame\n",
    "def csv_to_df(csv_path):\n",
    "    try:\n",
    "        # Leer el archivo CSV en un RDD de PySpark\n",
    "        csv_rdd = spark.sparkContext.textFile(csv_path)\n",
    "        #csv_rdd = spark.sparkContext.textFile(csv_path, use_unicode=False, quote='\"')\n",
    "\n",
    "        # Obtener la primera fila\n",
    "        header = csv_rdd.first()\n",
    "        \n",
    "        # Contar los elementos de la primera fila\n",
    "        num_columns = len(header.split(\",\"))\n",
    "\n",
    "        # Dividir cada línea del RDD en una lista de valores\n",
    "        csv_rdd = csv_rdd.map(lambda x: x.split(\",\"))\n",
    "        \n",
    "        # Se excluye el primer registro\n",
    "        csv_rdd = csv_rdd.zipWithIndex().filter(lambda x: x[1] > 0).map(lambda x: x[0])\n",
    "\n",
    "        # Convertir el RDD en un DataFrame de PySpark, \n",
    "        df = spark.createDataFrame(csv_rdd)\n",
    "\n",
    "        # Imprimir el número de columnas del archivo CSV\n",
    "        print(f\"El archivo '{csv_path}' tiene {num_columns} columnas\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # Imprimir un mensaje de error si ocurre una excepción durante la lectura del archivo\n",
    "        print(f\"Error al leer el archivo '{csv_path}': {e}\")\n",
    "        df = None\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-implement",
   "metadata": {},
   "source": [
    "### Leer y escrbir en parquet el archivo country_wise_latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "designing-webster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo 'covid19/country_wise_latest.csv' tiene 15 columnas\n"
     ]
    }
   ],
   "source": [
    "# Convertir el archivo country_wise_latest en Dataframe, el archivo debe tener 15 columnas\n",
    "df_cwl = csv_to_df(\"covid19/country_wise_latest.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "geological-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Castear los campos\n",
    "df_cwl = df_cwl.withColumn(\"CountryRegion\", df_cwl[\"_1\"].cast(StringType())).drop(\"_1\")\n",
    "df_cwl = df_cwl.withColumn(\"Confirmed\", df_cwl[\"_2\"].cast(IntegerType())).drop(\"_2\")\n",
    "df_cwl = df_cwl.withColumn(\"Deaths\", df_cwl[\"_3\"].cast(IntegerType())).drop(\"_3\")\n",
    "df_cwl = df_cwl.withColumn(\"Recovered\", df_cwl[\"_4\"].cast(IntegerType())).drop(\"_4\")\n",
    "df_cwl = df_cwl.withColumn(\"Active\", df_cwl[\"_5\"].cast(IntegerType())).drop(\"_5\")\n",
    "df_cwl = df_cwl.withColumn(\"NewCases\", df_cwl[\"_6\"].cast(IntegerType())).drop(\"_6\")\n",
    "df_cwl = df_cwl.withColumn(\"NewDeaths\", df_cwl[\"_7\"].cast(IntegerType())).drop(\"_7\")\n",
    "df_cwl = df_cwl.withColumn(\"NewRecovered\", df_cwl[\"_8\"].cast(IntegerType())).drop(\"_8\")\n",
    "df_cwl = df_cwl.withColumn(\"Deaths100Cases\", df_cwl[\"_9\"].cast(DoubleType())).drop(\"_9\")\n",
    "df_cwl = df_cwl.withColumn(\"Recovered100Cases\", df_cwl[\"_10\"].cast(DoubleType())).drop(\"_10\")\n",
    "df_cwl = df_cwl.withColumn(\"Deaths100Recovered\", df_cwl[\"_11\"].cast(DoubleType())).drop(\"_11\")\n",
    "df_cwl = df_cwl.withColumn(\"ConfirmedLastWeek\", df_cwl[\"_12\"].cast(IntegerType())).drop(\"_12\")\n",
    "df_cwl = df_cwl.withColumn(\"1WeekChange\", df_cwl[\"_13\"].cast(IntegerType())).drop(\"_13\")\n",
    "df_cwl = df_cwl.withColumn(\"1WeekIncrease\", df_cwl[\"_14\"].cast(DoubleType())).drop(\"_14\")\n",
    "df_cwl = df_cwl.withColumn(\"WhoRegion\", df_cwl[\"_15\"].cast(StringType())).drop(\"_15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fabulous-nursing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+------+---------+------+--------+---------+------------+--------------+-----------------+------------------+-----------------+-----------+-------------+--------------------+\n",
      "|CountryRegion|Confirmed|Deaths|Recovered|Active|NewCases|NewDeaths|NewRecovered|Deaths100Cases|Recovered100Cases|Deaths100Recovered|ConfirmedLastWeek|1WeekChange|1WeekIncrease|           WhoRegion|\n",
      "+-------------+---------+------+---------+------+--------+---------+------------+--------------+-----------------+------------------+-----------------+-----------+-------------+--------------------+\n",
      "|  Afghanistan|    36263|  1269|    25198|  9796|     106|       10|          18|           3.5|            69.49|              5.04|            35526|        737|         2.07|Eastern Mediterra...|\n",
      "|      Albania|     4880|   144|     2745|  1991|     117|        6|          63|          2.95|            56.25|              5.25|             4171|        709|         17.0|              Europe|\n",
      "|      Algeria|    27973|  1163|    18837|  7973|     616|        8|         749|          4.16|            67.34|              6.17|            23691|       4282|        18.07|              Africa|\n",
      "|      Andorra|      907|    52|      803|    52|      10|        0|           0|          5.73|            88.53|              6.48|              884|         23|          2.6|              Europe|\n",
      "|       Angola|      950|    41|      242|   667|      18|        1|           0|          4.32|            25.47|             16.94|              749|        201|        26.84|              Africa|\n",
      "+-------------+---------+------+---------+------+--------+---------+------------+--------------+-----------------+------------------+-----------------+-----------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validar el data Frame\n",
    "df_cwl.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fundamental-style",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribir parquet\n",
    "df_cwl.write.parquet(\"covid19/country_wise_latest.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-elizabeth",
   "metadata": {},
   "source": [
    "### Leer y escrbir en parquet el archivo covid_19_clean_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "alert-costa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo 'covid19/covid_19_clean_complete.csv' tiene 10 columnas\n"
     ]
    }
   ],
   "source": [
    "# Convertir el archivo covid_19_clean_complete en Dataframe, el archivo debe tener 10 columnas\n",
    "df_ccc = csv_to_df(\"covid19/covid_19_clean_complete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "crazy-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Castear los campos\n",
    "df_ccc = df_ccc.withColumn(\"ProvinceState\", df_ccc[\"_1\"].cast(StringType())).drop(\"_1\")\n",
    "df_ccc = df_ccc.withColumn(\"CountryRegion\", df_ccc[\"_2\"].cast(StringType())).drop(\"_2\")\n",
    "df_ccc = df_ccc.withColumn(\"Lat\", df_ccc[\"_3\"].cast(DoubleType())).drop(\"_3\")\n",
    "df_ccc = df_ccc.withColumn(\"Long\", df_ccc[\"_4\"].cast(DoubleType())).drop(\"_4\")\n",
    "df_ccc = df_ccc.withColumn(\"Date\", df_ccc[\"_5\"].cast(DateType())).drop(\"_5\")\n",
    "df_ccc = df_ccc.withColumn(\"Confirmed\", df_ccc[\"_6\"].cast(IntegerType())).drop(\"_6\")\n",
    "df_ccc = df_ccc.withColumn(\"Deaths\", df_ccc[\"_7\"].cast(IntegerType())).drop(\"_7\")\n",
    "df_ccc = df_ccc.withColumn(\"Recovered\", df_ccc[\"_8\"].cast(IntegerType())).drop(\"_8\")\n",
    "df_ccc = df_ccc.withColumn(\"Active\", df_ccc[\"_9\"].cast(IntegerType())).drop(\"_9\")\n",
    "df_ccc = df_ccc.withColumn(\"WhoRegion\", df_ccc[\"_10\"].cast(StringType())).drop(\"_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sought-blues",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------+---------+----------+---------+------+---------+------+--------------------+\n",
      "|       ProvinceState|      CountryRegion|     Lat|     Long|      Date|Confirmed|Deaths|Recovered|Active|           WhoRegion|\n",
      "+--------------------+-------------------+--------+---------+----------+---------+------+---------+------+--------------------+\n",
      "|                    |        Afghanistan|33.93911|67.709953|2020-01-22|        0|     0|        0|     0|Eastern Mediterra...|\n",
      "|                    |            Albania| 41.1533|  20.1683|2020-01-22|        0|     0|        0|     0|              Europe|\n",
      "|                    |            Algeria| 28.0339|   1.6596|2020-01-22|        0|     0|        0|     0|              Africa|\n",
      "|                    |            Andorra| 42.5063|   1.5218|2020-01-22|        0|     0|        0|     0|              Europe|\n",
      "|                    |             Angola|-11.2027|  17.8739|2020-01-22|        0|     0|        0|     0|              Africa|\n",
      "|                    |Antigua and Barbuda| 17.0608| -61.7964|2020-01-22|        0|     0|        0|     0|            Americas|\n",
      "|                    |          Argentina|-38.4161| -63.6167|2020-01-22|        0|     0|        0|     0|            Americas|\n",
      "|                    |            Armenia| 40.0691|  45.0382|2020-01-22|        0|     0|        0|     0|              Europe|\n",
      "|Australian Capita...|          Australia|-35.4735| 149.0124|2020-01-22|        0|     0|        0|     0|     Western Pacific|\n",
      "|     New South Wales|          Australia|-33.8688| 151.2093|2020-01-22|        0|     0|        0|     0|     Western Pacific|\n",
      "+--------------------+-------------------+--------+---------+----------+---------+------+---------+------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validar el data Frame\n",
    "df_ccc.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "massive-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribir parquet\n",
    "df_ccc.write.parquet(\"covid19/covid_19_clean_complete.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-gazette",
   "metadata": {},
   "source": [
    "### Leer y escrbir en parquet el archivo day_wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "average-channels",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo 'covid19/day_wise.csv' tiene 12 columnas\n"
     ]
    }
   ],
   "source": [
    "# Convertir el archivo day_wise en Dataframe, el archivo debe tener 12 columnas\n",
    "df_dw = csv_to_df(\"covid19/day_wise.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cooperative-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Castear los campos\n",
    "df_dw =  df_dw.withColumn(\"Date\",  df_dw[\"_1\"].cast(DateType())).drop(\"_1\")\n",
    "df_dw =  df_dw.withColumn(\"Confirmed\",  df_dw[\"_2\"].cast(IntegerType())).drop(\"_2\")\n",
    "df_dw =  df_dw.withColumn(\"Deaths\",  df_dw[\"_3\"].cast(IntegerType())).drop(\"_3\")\n",
    "df_dw =  df_dw.withColumn(\"Recovered\",  df_dw[\"_4\"].cast(IntegerType())).drop(\"_4\")\n",
    "df_dw =  df_dw.withColumn(\"Active\",  df_dw[\"_5\"].cast(IntegerType())).drop(\"_5\")\n",
    "df_dw =  df_dw.withColumn(\"NewCases\",  df_dw[\"_6\"].cast(IntegerType())).drop(\"_6\")\n",
    "df_dw =  df_dw.withColumn(\"NewDeaths\",  df_dw[\"_7\"].cast(IntegerType())).drop(\"_7\")\n",
    "df_dw =  df_dw.withColumn(\"NewRecovered\",  df_dw[\"_8\"].cast(IntegerType())).drop(\"_8\")\n",
    "df_dw =  df_dw.withColumn(\"Deaths100Cases\",  df_dw[\"_9\"].cast(DoubleType())).drop(\"_9\")\n",
    "df_dw =  df_dw.withColumn(\"Recovered100Cases\",  df_dw[\"_10\"].cast(DoubleType())).drop(\"_10\")\n",
    "df_dw =  df_dw.withColumn(\"Deaths100Recovered\",  df_dw[\"_11\"].cast(DoubleType())).drop(\"_11\")\n",
    "df_dw =  df_dw.withColumn(\"NoOfContries\",  df_dw[\"_12\"].cast(IntegerType())).drop(\"_12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "related-hormone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+---------+------+--------+---------+------------+--------------+-----------------+------------------+------------+\n",
      "|      Date|Confirmed|Deaths|Recovered|Active|NewCases|NewDeaths|NewRecovered|Deaths100Cases|Recovered100Cases|Deaths100Recovered|NoOfContries|\n",
      "+----------+---------+------+---------+------+--------+---------+------------+--------------+-----------------+------------------+------------+\n",
      "|2020-01-22|      555|    17|       28|   510|       0|        0|           0|          3.06|             5.05|             60.71|           6|\n",
      "|2020-01-23|      654|    18|       30|   606|      99|        1|           2|          2.75|             4.59|              60.0|           8|\n",
      "|2020-01-24|      941|    26|       36|   879|     287|        8|           6|          2.76|             3.83|             72.22|           9|\n",
      "|2020-01-25|     1434|    42|       39|  1353|     493|       16|           3|          2.93|             2.72|            107.69|          11|\n",
      "|2020-01-26|     2118|    56|       52|  2010|     684|       14|          13|          2.64|             2.46|            107.69|          13|\n",
      "+----------+---------+------+---------+------+--------+---------+------------+--------------+-----------------+------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validar el data Frame\n",
    "df_dw.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "prime-denver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribir parquet\n",
    "df_dw.write.parquet(\"covid19/day_wise.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-uganda",
   "metadata": {},
   "source": [
    "### Leer y escrbir en parquet el archivo full_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "private-hardwood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo 'covid19/full_grouped.csv' tiene 10 columnas\n"
     ]
    }
   ],
   "source": [
    "# Convertir el archivo full_grouped en Dataframe, el archivo debe tener 10 columnas\n",
    "df_fg = csv_to_df(\"covid19/full_grouped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "national-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Castear los campos\n",
    "df_fg =   df_fg.withColumn(\"Date\",   df_fg[\"_1\"].cast(DateType())).drop(\"_1\")\n",
    "df_fg =   df_fg.withColumn(\"CountryRegion\", df_fg[\"_2\"].cast(StringType())).drop(\"_2\")\n",
    "df_fg =  df_fg.withColumn(\"Confirmed\",  df_fg[\"_3\"].cast(IntegerType())).drop(\"_3\")\n",
    "df_fg =  df_fg.withColumn(\"Deaths\",  df_fg[\"_4\"].cast(IntegerType())).drop(\"_4\")\n",
    "df_fg =  df_fg.withColumn(\"Recovered\",  df_fg[\"_5\"].cast(IntegerType())).drop(\"_5\")\n",
    "df_fg =  df_fg.withColumn(\"Active\",  df_fg[\"_6\"].cast(IntegerType())).drop(\"_6\")\n",
    "df_fg =  df_fg.withColumn(\"NewCases\",  df_fg[\"_7\"].cast(IntegerType())).drop(\"_7\")\n",
    "df_fg =  df_fg.withColumn(\"NewDeaths\",  df_fg[\"_8\"].cast(IntegerType())).drop(\"_8\")\n",
    "df_fg =   df_fg.withColumn(\"NewRecovered\",   df_fg[\"_9\"].cast(IntegerType())).drop(\"_9\")\n",
    "df_fg =   df_fg.withColumn(\"WhoRegion\",   df_fg[\"_10\"].cast(StringType())).drop(\"_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "turkish-advisory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+---------+------+---------+------+--------+---------+------------+--------------------+\n",
      "|      Date|CountryRegion|Confirmed|Deaths|Recovered|Active|NewCases|NewDeaths|NewRecovered|           WhoRegion|\n",
      "+----------+-------------+---------+------+---------+------+--------+---------+------------+--------------------+\n",
      "|2020-01-22|  Afghanistan|        0|     0|        0|     0|       0|        0|           0|Eastern Mediterra...|\n",
      "|2020-01-22|      Albania|        0|     0|        0|     0|       0|        0|           0|              Europe|\n",
      "|2020-01-22|      Algeria|        0|     0|        0|     0|       0|        0|           0|              Africa|\n",
      "|2020-01-22|      Andorra|        0|     0|        0|     0|       0|        0|           0|              Europe|\n",
      "|2020-01-22|       Angola|        0|     0|        0|     0|       0|        0|           0|              Africa|\n",
      "+----------+-------------+---------+------+---------+------+--------+---------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validar el data Frame\n",
    "df_fg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "demographic-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribir parquet\n",
    "df_dw.write.parquet(\"covid19/full_grouped.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-pathology",
   "metadata": {},
   "source": [
    "### Leer y escrbir en parquet el archivo worldometer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "qualified-aside",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo 'covid19/worldometer_data.csv' tiene 17 columnas\n"
     ]
    }
   ],
   "source": [
    "# Convertir el archivo worldometer_data en Dataframe \n",
    "# El archivo debe tener 16 columnas pero al cargar dice 17 porque dentro de los titulos de columna hay una coma.\n",
    "df_wd = csv_to_df(\"covid19/worldometer_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "rapid-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Castear los campos\n",
    "df_wd = df_wd.withColumn(\"CountryRegion\", df_wd[\"_1\"].cast(StringType())).drop(\"_1\")\n",
    "df_wd = df_wd.withColumn(\"Continent\", df_wd[\"_2\"].cast(StringType())).drop(\"_2\")\n",
    "df_wd = df_wd.withColumn(\"Population\", df_wd[\"_3\"].cast(IntegerType())).drop(\"_3\")\n",
    "df_wd = df_wd.withColumn(\"TotalCases\", df_wd[\"_4\"].cast(IntegerType())).drop(\"_4\")\n",
    "df_wd = df_wd.withColumn(\"NewCases\", df_wd[\"_5\"].cast(IntegerType())).drop(\"_5\")\n",
    "df_wd = df_wd.withColumn(\"TotalDeaths\", df_wd[\"_6\"].cast(IntegerType())).drop(\"_6\")\n",
    "df_wd = df_wd.withColumn(\"NewDeaths\", df_wd[\"_7\"].cast(IntegerType())).drop(\"_7\")\n",
    "df_wd = df_wd.withColumn(\"TotalRecovered\", df_wd[\"_8\"].cast(IntegerType())).drop(\"_8\")\n",
    "df_wd = df_wd.withColumn(\"NewRecovered\", df_wd[\"_9\"].cast(IntegerType())).drop(\"_9\")\n",
    "df_wd = df_wd.withColumn(\"ActiveCases\", df_wd[\"_10\"].cast(IntegerType())).drop(\"_10\")\n",
    "df_wd = df_wd.withColumn(\"SeriousCritical\", df_wd[\"_11\"].cast(DoubleType())).drop(\"_11\")\n",
    "df_wd = df_wd.withColumn(\"TotCases1MPop\", df_wd[\"_12\"].cast(IntegerType())).drop(\"_12\")\n",
    "df_wd = df_wd.withColumn(\"Deaths1MPop\", df_wd[\"_13\"].cast(IntegerType())).drop(\"_13\")\n",
    "df_wd = df_wd.withColumn(\"TotalTests\", df_wd[\"_14\"].cast(IntegerType())).drop(\"_14\")\n",
    "df_wd = df_wd.withColumn(\"Tests1MPop\", df_wd[\"_15\"].cast(IntegerType())).drop(\"_15\")\n",
    "df_wd = df_wd.withColumn(\"Region\", df_wd[\"_16\"].cast(StringType())).drop(\"_16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "informative-heavy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+----------+----------+--------+-----------+---------+--------------+------------+-----------+---------------+-------------+-----------+----------+----------+--------------+\n",
      "|CountryRegion|    Continent|Population|TotalCases|NewCases|TotalDeaths|NewDeaths|TotalRecovered|NewRecovered|ActiveCases|SeriousCritical|TotCases1MPop|Deaths1MPop|TotalTests|Tests1MPop|        Region|\n",
      "+-------------+-------------+----------+----------+--------+-----------+---------+--------------+------------+-----------+---------------+-------------+-----------+----------+----------+--------------+\n",
      "|          USA|North America| 331198130|   5032179|    null|     162804|     null|       2576668|        null|    2292707|        18296.0|        15194|        492|  63139605|    190640|      Americas|\n",
      "|       Brazil|South America| 212710692|   2917562|    null|      98644|     null|       2047660|        null|     771258|         8318.0|        13716|        464|  13206188|     62085|      Americas|\n",
      "|        India|         Asia|1381344997|   2025409|    null|      41638|     null|       1377384|        null|     606387|         8944.0|         1466|         30|  22149351|     16035|South-EastAsia|\n",
      "|       Russia|       Europe| 145940924|    871894|    null|      14606|     null|        676357|        null|     180931|         2300.0|         5974|        100|  29716907|    203623|        Europe|\n",
      "| South Africa|       Africa|  59381566|    538184|    null|       9604|     null|        387316|        null|     141264|          539.0|         9063|        162|   3149807|     53044|        Africa|\n",
      "+-------------+-------------+----------+----------+--------+-----------+---------+--------------+------------+-----------+---------------+-------------+-----------+----------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validar el data Frame\n",
    "df_wd.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "elementary-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribir parquet\n",
    "df_dw.write.parquet(\"covid19/worldometer_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-hindu",
   "metadata": {},
   "source": [
    "### Leer y escrbir en parquet el archivo usa_county_wise   \n",
    "Con este archivo si tocó leerlo directo en un dataframe porque dentro del archivo vienen textos con comas.\n",
    "Personalemnte prefiero usar DataFrame en lugar de la API de RDD siempre que sea posible, ya que los DataFrames ofrecen mejor rendimiento y la interfaz es mejor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "forbidden-frank",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer archivo usa_county_wise directamente a un DataFrame\n",
    "df_ucw = spark.read.option(\"header\", \"true\").option(\"sep\", \",\").option(\"quote\", '\"').csv(\"covid19/usa_county_wise.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "laughing-radiation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----+-----+-------+--------+--------------------+--------------+-------------------+------------------+--------------------+-------+---------+------+\n",
      "|     UID|iso2|iso3|code3|   FIPS|  Admin2|      Province_State|Country_Region|                Lat|             Long_|        Combined_Key|   Date|Confirmed|Deaths|\n",
      "+--------+----+----+-----+-------+--------+--------------------+--------------+-------------------+------------------+--------------------+-------+---------+------+\n",
      "|      16|  AS| ASM|   16|   60.0|    null|      American Samoa|            US|-14.270999999999999|          -170.132|  American Samoa, US|1/22/20|        0|     0|\n",
      "|     316|  GU| GUM|  316|   66.0|    null|                Guam|            US|            13.4443|          144.7937|            Guam, US|1/22/20|        0|     0|\n",
      "|     580|  MP| MNP|  580|   69.0|    null|Northern Mariana ...|            US|            15.0979|          145.6739|Northern Mariana ...|1/22/20|        0|     0|\n",
      "|63072001|  PR| PRI|  630|72001.0|Adjuntas|         Puerto Rico|            US| 18.180117000000006|        -66.754367|Adjuntas, Puerto ...|1/22/20|        0|     0|\n",
      "|63072003|  PR| PRI|  630|72003.0|  Aguada|         Puerto Rico|            US|          18.360255|-67.17513100000001|Aguada, Puerto Ri...|1/22/20|        0|     0|\n",
      "+--------+----+----+-----+-------+--------+--------------------+--------------+-------------------+------------------+--------------------+-------+---------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validar que se haya leido bien el archivo, es decir, que no se haya afectado la lectura por las comas dentro de los campos texto\n",
    "df_ucw.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "balanced-charge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de columnas: 14\n"
     ]
    }
   ],
   "source": [
    "# Validar el nuemro de columnas, deben ser 14.\n",
    "print(\"Número de columnas:\", len(df_ucw.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "scheduled-helen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Castear los campos\n",
    "df_ucw = df_ucw.withColumn(\"UID\", df_ucw[\"UID\"].cast(IntegerType()))\n",
    "df_ucw = df_ucw.withColumnRenamed(\"iso2\", \"ISO2\")\n",
    "df_ucw = df_ucw.withColumnRenamed(\"iso3\", \"ISO3\") \n",
    "df_ucw = df_ucw.withColumnRenamed(\"code3\", \"Code3\")## Hago esto para mantener el orden de las columnas\n",
    "df_ucw = df_ucw.withColumn(\"Code3\", df_ucw[\"Code3\"].cast(IntegerType()))\n",
    "df_ucw = df_ucw.withColumn(\"FIPS\", df_ucw[\"FIPS\"].cast(DoubleType()))\n",
    "df_ucw = df_ucw.withColumnRenamed(\"Admin2\",\"Admin2\")\n",
    "df_ucw = df_ucw.withColumnRenamed(\"Province_State\",\"ProvinceState\")\n",
    "df_ucw = df_ucw.withColumnRenamed(\"Country_Region\",\"CountryRegion\")\n",
    "df_ucw = df_ucw.withColumn(\"Lat\", df_ucw[\"Lat\"].cast(DoubleType()))\n",
    "df_ucw = df_ucw.withColumnRenamed(\"Long_\",\"Long\")## Hago esto para mantener el orden de las columnas\n",
    "df_ucw = df_ucw.withColumn(\"Long\", df_ucw[\"Long\"].cast(DoubleType()))\n",
    "df_ucw = df_ucw.withColumnRenamed(\"Combined_Key\",\"CombinedKey\")\n",
    "df_ucw = df_ucw.withColumn(\"Date\", df_ucw[\"Date\"].cast(DateType()))\n",
    "df_ucw = df_ucw.withColumn(\"Confirmed\", df_ucw[\"Confirmed\"].cast(IntegerType()))\n",
    "df_ucw = df_ucw.withColumn(\"Deaths\", df_ucw[\"Deaths\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "indoor-gallery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----+-----+-------+--------+--------------------+-------------+-------------------+------------------+--------------------+----+---------+------+\n",
      "|     UID|ISO2|ISO3|Code3|   FIPS|  Admin2|       ProvinceState|CountryRegion|                Lat|              Long|         CombinedKey|Date|Confirmed|Deaths|\n",
      "+--------+----+----+-----+-------+--------+--------------------+-------------+-------------------+------------------+--------------------+----+---------+------+\n",
      "|      16|  AS| ASM|   16|   60.0|    null|      American Samoa|           US|-14.270999999999999|          -170.132|  American Samoa, US|null|        0|     0|\n",
      "|     316|  GU| GUM|  316|   66.0|    null|                Guam|           US|            13.4443|          144.7937|            Guam, US|null|        0|     0|\n",
      "|     580|  MP| MNP|  580|   69.0|    null|Northern Mariana ...|           US|            15.0979|          145.6739|Northern Mariana ...|null|        0|     0|\n",
      "|63072001|  PR| PRI|  630|72001.0|Adjuntas|         Puerto Rico|           US| 18.180117000000006|        -66.754367|Adjuntas, Puerto ...|null|        0|     0|\n",
      "|63072003|  PR| PRI|  630|72003.0|  Aguada|         Puerto Rico|           US|          18.360255|-67.17513100000001|Aguada, Puerto Ri...|null|        0|     0|\n",
      "+--------+----+----+-----+-------+--------+--------------------+-------------+-------------------+------------------+--------------------+----+---------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validar el data Frame\n",
    "df_ucw.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "applied-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribir parquet\n",
    "df_ucw.write.parquet(\"covid19/usa_county_wise.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acquired-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detener la sesión de Spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-representative",
   "metadata": {},
   "source": [
    "## Cargar Información utilizando Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dirty-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-terror",
   "metadata": {},
   "source": [
    "### Cargar el archivo country_wise_latest utilizando pandas y escribir archivo parquet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "tribal-builder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de columnas: 15\n"
     ]
    }
   ],
   "source": [
    "# Cargar en un DtaFrame de pandas\n",
    "df_cwlpd = pd.read_csv(\"covid19/country_wise_latest.csv\", sep=',', quotechar='\"')\n",
    "\n",
    "# Contar número de columnas, Deben ser 15 columnas\n",
    "print(\"Número de columnas:\", df_cwlpd.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "addressed-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corregir el nombre de las columnas\n",
    "df_cwlpd.columns = ['CountryRegion', 'Confirmed', 'Deaths','Recovered','Active','NewCases','NewDeaths','NewRecovered','Deaths100Cases','Recovered100Cases','Deaths100Recovered','ConfirmedLastWeek','1WeekChange','1WeekIncrease','WhoRegion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "professional-prophet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          CountryRegion  Confirmed  Deaths  Recovered  Active  NewCases  \\\n",
      "0           Afghanistan      36263    1269      25198    9796       106   \n",
      "1               Albania       4880     144       2745    1991       117   \n",
      "2               Algeria      27973    1163      18837    7973       616   \n",
      "3               Andorra        907      52        803      52        10   \n",
      "4                Angola        950      41        242     667        18   \n",
      "..                  ...        ...     ...        ...     ...       ...   \n",
      "182  West Bank and Gaza      10621      78       3752    6791       152   \n",
      "183      Western Sahara         10       1          8       1         0   \n",
      "184               Yemen       1691     483        833     375        10   \n",
      "185              Zambia       4552     140       2815    1597        71   \n",
      "186            Zimbabwe       2704      36        542    2126       192   \n",
      "\n",
      "     NewDeaths  NewRecovered  Deaths100Cases  Recovered100Cases  \\\n",
      "0           10            18            3.50              69.49   \n",
      "1            6            63            2.95              56.25   \n",
      "2            8           749            4.16              67.34   \n",
      "3            0             0            5.73              88.53   \n",
      "4            1             0            4.32              25.47   \n",
      "..         ...           ...             ...                ...   \n",
      "182          2             0            0.73              35.33   \n",
      "183          0             0           10.00              80.00   \n",
      "184          4            36           28.56              49.26   \n",
      "185          1           465            3.08              61.84   \n",
      "186          2            24            1.33              20.04   \n",
      "\n",
      "     Deaths100Recovered  ConfirmedLastWeek  1WeekChange  1WeekIncrease  \\\n",
      "0                  5.04              35526          737           2.07   \n",
      "1                  5.25               4171          709          17.00   \n",
      "2                  6.17              23691         4282          18.07   \n",
      "3                  6.48                884           23           2.60   \n",
      "4                 16.94                749          201          26.84   \n",
      "..                  ...                ...          ...            ...   \n",
      "182                2.08               8916         1705          19.12   \n",
      "183               12.50                 10            0           0.00   \n",
      "184               57.98               1619           72           4.45   \n",
      "185                4.97               3326         1226          36.86   \n",
      "186                6.64               1713          991          57.85   \n",
      "\n",
      "                 WhoRegion  \n",
      "0    Eastern Mediterranean  \n",
      "1                   Europe  \n",
      "2                   Africa  \n",
      "3                   Europe  \n",
      "4                   Africa  \n",
      "..                     ...  \n",
      "182  Eastern Mediterranean  \n",
      "183                 Africa  \n",
      "184  Eastern Mediterranean  \n",
      "185                 Africa  \n",
      "186                 Africa  \n",
      "\n",
      "[187 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "# Validar el Dataframe\n",
    "print(df_cwlpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "split-journalist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountryRegion          object\n",
      "Confirmed               int64\n",
      "Deaths                  int64\n",
      "Recovered               int64\n",
      "Active                  int64\n",
      "NewCases                int64\n",
      "NewDeaths               int64\n",
      "NewRecovered            int64\n",
      "Deaths100Cases        float64\n",
      "Recovered100Cases     float64\n",
      "Deaths100Recovered    float64\n",
      "ConfirmedLastWeek       int64\n",
      "1WeekChange             int64\n",
      "1WeekIncrease         float64\n",
      "WhoRegion              object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Validar que los tipos de datos sean los correctos\n",
    "print(df_cwlpd.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "current-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribir el dataframe\n",
    "df_cwlpd.to_parquet('covid19/pd/country_wise_latest.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-auction",
   "metadata": {},
   "source": [
    "### Cargar el archivo covid_19_clean_complete utilizando pandas y escribir archivo parquet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "future-namibia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de columnas: 10\n"
     ]
    }
   ],
   "source": [
    "# Cargar en un DtaFrame de pandas\n",
    "df_cccpd = pd.read_csv(\"covid19/covid_19_clean_complete.csv\", sep=',', quotechar='\"')\n",
    "\n",
    "# Contar número de columnas, Deben ser 10 columnas\n",
    "print(\"Número de columnas:\", df_cccpd.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "entire-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corregir el nombre de las columnas\n",
    "df_cccpd.columns = ['ProvinceState', 'CountryRegion', 'Lat','Long','Date','Confirmed','Deaths','Recovered','Active','WhoRegion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "liquid-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar casteo \n",
    "df_cccpd['Date'] = pd.to_datetime(df_cccpd['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "committed-closing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProvinceState            object\n",
      "CountryRegion            object\n",
      "Lat                     float64\n",
      "Long                    float64\n",
      "Date             datetime64[ns]\n",
      "Confirmed                 int64\n",
      "Deaths                    int64\n",
      "Recovered                 int64\n",
      "Active                    int64\n",
      "WhoRegion                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Validar que los tipos de datos sean los correctos\n",
    "print(df_cccpd.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "quantitative-internship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ProvinceState          CountryRegion        Lat       Long       Date  \\\n",
      "0               NaN            Afghanistan  33.939110  67.709953 2020-01-22   \n",
      "1               NaN                Albania  41.153300  20.168300 2020-01-22   \n",
      "2               NaN                Algeria  28.033900   1.659600 2020-01-22   \n",
      "3               NaN                Andorra  42.506300   1.521800 2020-01-22   \n",
      "4               NaN                 Angola -11.202700  17.873900 2020-01-22   \n",
      "...             ...                    ...        ...        ...        ...   \n",
      "49063           NaN  Sao Tome and Principe   0.186400   6.613100 2020-07-27   \n",
      "49064           NaN                  Yemen  15.552727  48.516388 2020-07-27   \n",
      "49065           NaN                Comoros -11.645500  43.333300 2020-07-27   \n",
      "49066           NaN             Tajikistan  38.861000  71.276100 2020-07-27   \n",
      "49067           NaN                Lesotho -29.610000  28.233600 2020-07-27   \n",
      "\n",
      "       Confirmed  Deaths  Recovered  Active              WhoRegion  \n",
      "0              0       0          0       0  Eastern Mediterranean  \n",
      "1              0       0          0       0                 Europe  \n",
      "2              0       0          0       0                 Africa  \n",
      "3              0       0          0       0                 Europe  \n",
      "4              0       0          0       0                 Africa  \n",
      "...          ...     ...        ...     ...                    ...  \n",
      "49063        865      14        734     117                 Africa  \n",
      "49064       1691     483        833     375  Eastern Mediterranean  \n",
      "49065        354       7        328      19                 Africa  \n",
      "49066       7235      60       6028    1147                 Europe  \n",
      "49067        505      12        128     365                 Africa  \n",
      "\n",
      "[49068 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Validar el Dataframe\n",
    "print(df_cccpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "other-denver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribir el dataframe\n",
    "df_cccpd.to_parquet('covid19/pd/covid_19_clean_complete.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-policy",
   "metadata": {},
   "source": [
    "### Cargar el archivo day_wise utilizando pandas y escribir archivo parquet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "radio-excellence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de columnas: 12\n"
     ]
    }
   ],
   "source": [
    "# Cargar en un DtaFrame de pandas\n",
    "df_dwpd = pd.read_csv(\"covid19/day_wise.csv\", sep=',', quotechar='\"')\n",
    "\n",
    "# Contar número de columnas, Deben ser 12 columnas\n",
    "print(\"Número de columnas:\", df_dwpd.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "effective-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corregir el nombre de las columnas\n",
    "df_dwpd.columns = ['Date', 'Confirmed', 'Deaths','Recovered','Active','NewCases','NewDeaths','NewRecovered','Deaths100Cases','Recovered100Cases','Deaths100Recovered','NoOfContries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "psychological-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar casteo de las columnas\n",
    "df_dwpd['Date'] = pd.to_datetime(df_dwpd['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "particular-burning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                  datetime64[ns]\n",
      "Confirmed                      int64\n",
      "Deaths                         int64\n",
      "Recovered                      int64\n",
      "Active                         int64\n",
      "NewCases                       int64\n",
      "NewDeaths                      int64\n",
      "NewRecovered                   int64\n",
      "Deaths100Cases               float64\n",
      "Recovered100Cases            float64\n",
      "Deaths100Recovered           float64\n",
      "NoOfContries                   int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Validar que los tipos de datos sean los correctos\n",
    "print(df_dwpd.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cooked-flight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  Confirmed  Deaths  Recovered   Active  NewCases  NewDeaths  \\\n",
      "0   2020-01-22        555      17         28      510         0          0   \n",
      "1   2020-01-23        654      18         30      606        99          1   \n",
      "2   2020-01-24        941      26         36      879       287          8   \n",
      "3   2020-01-25       1434      42         39     1353       493         16   \n",
      "4   2020-01-26       2118      56         52     2010       684         14   \n",
      "..         ...        ...     ...        ...      ...       ...        ...   \n",
      "183 2020-07-23   15510481  633506    8710969  6166006    282756       9966   \n",
      "184 2020-07-24   15791645  639650    8939705  6212290    281164       6144   \n",
      "185 2020-07-25   16047190  644517    9158743  6243930    255545       4867   \n",
      "186 2020-07-26   16251796  648621    9293464  6309711    204606       4104   \n",
      "187 2020-07-27   16480485  654036    9468087  6358362    228693       5415   \n",
      "\n",
      "     NewRecovered  Deaths100Cases  Recovered100Cases  Deaths100Recovered  \\\n",
      "0               0            3.06               5.05               60.71   \n",
      "1               2            2.75               4.59               60.00   \n",
      "2               6            2.76               3.83               72.22   \n",
      "3               3            2.93               2.72              107.69   \n",
      "4              13            2.64               2.46              107.69   \n",
      "..            ...             ...                ...                 ...   \n",
      "183        169714            4.08              56.16                7.27   \n",
      "184        228736            4.05              56.61                7.16   \n",
      "185        219038            4.02              57.07                7.04   \n",
      "186        134721            3.99              57.18                6.98   \n",
      "187        174623            3.97              57.45                6.91   \n",
      "\n",
      "     NoOfContries  \n",
      "0               6  \n",
      "1               8  \n",
      "2               9  \n",
      "3              11  \n",
      "4              13  \n",
      "..            ...  \n",
      "183           187  \n",
      "184           187  \n",
      "185           187  \n",
      "186           187  \n",
      "187           187  \n",
      "\n",
      "[188 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Validar el Dataframe\n",
    "print(df_dwpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "empirical-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribir el dataframe\n",
    "df_dwpd.to_parquet('covid19/pd/day_wise.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-strategy",
   "metadata": {},
   "source": [
    "### Cargar el archivo full_grouped utilizando pandas y escribir archivo parquet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "intensive-dakota",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de columnas: 10\n"
     ]
    }
   ],
   "source": [
    "# Cargar en un DtaFrame de pandas\n",
    "df_fgpd = pd.read_csv(\"covid19/full_grouped.csv\", sep=',', quotechar='\"')\n",
    "\n",
    "# Contar número de columnas, Deben ser 10 columnas\n",
    "print(\"Número de columnas:\", df_fgpd.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "elegant-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corregir el nombre de las columnas\n",
    "df_fgpd.columns = ['Date', 'CountryRegion', 'Confirmed','Deaths','Recovered','Active','NewCases','NewDeaths','NewRecovered','WhoRegion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "found-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar casteo \n",
    "df_fgpd['Date'] = pd.to_datetime(df_fgpd['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "authorized-charm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date             datetime64[ns]\n",
      "CountryRegion            object\n",
      "Confirmed                 int64\n",
      "Deaths                    int64\n",
      "Recovered                 int64\n",
      "Active                    int64\n",
      "NewCases                  int64\n",
      "NewDeaths                 int64\n",
      "NewRecovered              int64\n",
      "WhoRegion                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Validar que los tipos de datos sean los correctos\n",
    "print(df_fgpd.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "reasonable-martin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date       CountryRegion  Confirmed  Deaths  Recovered  Active  \\\n",
      "0     2020-01-22         Afghanistan          0       0          0       0   \n",
      "1     2020-01-22             Albania          0       0          0       0   \n",
      "2     2020-01-22             Algeria          0       0          0       0   \n",
      "3     2020-01-22             Andorra          0       0          0       0   \n",
      "4     2020-01-22              Angola          0       0          0       0   \n",
      "...          ...                 ...        ...     ...        ...     ...   \n",
      "35151 2020-07-27  West Bank and Gaza      10621      78       3752    6791   \n",
      "35152 2020-07-27      Western Sahara         10       1          8       1   \n",
      "35153 2020-07-27               Yemen       1691     483        833     375   \n",
      "35154 2020-07-27              Zambia       4552     140       2815    1597   \n",
      "35155 2020-07-27            Zimbabwe       2704      36        542    2126   \n",
      "\n",
      "       NewCases  NewDeaths  NewRecovered              WhoRegion  \n",
      "0             0          0             0  Eastern Mediterranean  \n",
      "1             0          0             0                 Europe  \n",
      "2             0          0             0                 Africa  \n",
      "3             0          0             0                 Europe  \n",
      "4             0          0             0                 Africa  \n",
      "...         ...        ...           ...                    ...  \n",
      "35151       152          2             0  Eastern Mediterranean  \n",
      "35152         0          0             0                 Africa  \n",
      "35153        10          4            36  Eastern Mediterranean  \n",
      "35154        71          1           465                 Africa  \n",
      "35155       192          2            24                 Africa  \n",
      "\n",
      "[35156 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Validar el Dataframe\n",
    "print(df_fgpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "significant-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribir el dataframe\n",
    "df_fgpd.to_parquet('covid19/pd/full_grouped.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-firmware",
   "metadata": {},
   "source": [
    "### Cargar el archivo usa_county_wise utilizando pandas y escribir archivo parquet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ultimate-transformation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de columnas: 14\n"
     ]
    }
   ],
   "source": [
    "# Cargar en un DtaFrame de pandas\n",
    "df_ucwpd = pd.read_csv(\"covid19/usa_county_wise.csv\", sep=',', quotechar='\"')\n",
    "\n",
    "# Contar número de columnas, Deben ser 14 columnas\n",
    "print(\"Número de columnas:\", df_ucwpd.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "happy-judgment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corregir el nombre de las columnas\n",
    "df_ucwpd.columns = ['UID', 'ISO2', 'ISO3','Code3','FIPS','Admin2','ProvinceState','CountryRegion','Lat','Long','CombinedKey','Date','Confirmed','Deaths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "diverse-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar casteo \n",
    "df_ucwpd['Date'] = pd.to_datetime(df_ucwpd['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "hearing-silence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UID                       int64\n",
      "ISO2                     object\n",
      "ISO3                     object\n",
      "Code3                     int64\n",
      "FIPS                    float64\n",
      "Admin2                   object\n",
      "ProvinceState            object\n",
      "CountryRegion            object\n",
      "Lat                     float64\n",
      "Long                    float64\n",
      "CombinedKey              object\n",
      "Date             datetime64[ns]\n",
      "Confirmed                 int64\n",
      "Deaths                    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Validar que los tipos de datos sean los correctos\n",
    "print(df_ucwpd.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cross-pharmaceutical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             UID ISO2 ISO3  Code3     FIPS          Admin2  \\\n",
      "0             16   AS  ASM     16     60.0             NaN   \n",
      "1            316   GU  GUM    316     66.0             NaN   \n",
      "2            580   MP  MNP    580     69.0             NaN   \n",
      "3       63072001   PR  PRI    630  72001.0        Adjuntas   \n",
      "4       63072003   PR  PRI    630  72003.0          Aguada   \n",
      "...          ...  ...  ...    ...      ...             ...   \n",
      "627915  84070016   US  USA    840      NaN    Central Utah   \n",
      "627916  84070017   US  USA    840      NaN  Southeast Utah   \n",
      "627917  84070018   US  USA    840      NaN  Southwest Utah   \n",
      "627918  84070019   US  USA    840      NaN       TriCounty   \n",
      "627919  84070020   US  USA    840      NaN    Weber-Morgan   \n",
      "\n",
      "                   ProvinceState CountryRegion        Lat        Long  \\\n",
      "0                 American Samoa            US -14.271000 -170.132000   \n",
      "1                           Guam            US  13.444300  144.793700   \n",
      "2       Northern Mariana Islands            US  15.097900  145.673900   \n",
      "3                    Puerto Rico            US  18.180117  -66.754367   \n",
      "4                    Puerto Rico            US  18.360255  -67.175131   \n",
      "...                          ...           ...        ...         ...   \n",
      "627915                      Utah            US  39.372319 -111.575868   \n",
      "627916                      Utah            US  38.996171 -110.701396   \n",
      "627917                      Utah            US  37.854472 -111.441876   \n",
      "627918                      Utah            US  40.124915 -109.517442   \n",
      "627919                      Utah            US  41.271160 -111.914512   \n",
      "\n",
      "                         CombinedKey       Date  Confirmed  Deaths  \n",
      "0                 American Samoa, US 2020-01-22          0       0  \n",
      "1                           Guam, US 2020-01-22          0       0  \n",
      "2       Northern Mariana Islands, US 2020-01-22          0       0  \n",
      "3          Adjuntas, Puerto Rico, US 2020-01-22          0       0  \n",
      "4            Aguada, Puerto Rico, US 2020-01-22          0       0  \n",
      "...                              ...        ...        ...     ...  \n",
      "627915        Central Utah, Utah, US 2020-07-27        347       1  \n",
      "627916      Southeast Utah, Utah, US 2020-07-27         70       0  \n",
      "627917      Southwest Utah, Utah, US 2020-07-27       2781      23  \n",
      "627918           TriCounty, Utah, US 2020-07-27        142       0  \n",
      "627919        Weber-Morgan, Utah, US 2020-07-27       2375      24  \n",
      "\n",
      "[627920 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Validar el Dataframe\n",
    "print(df_ucwpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "opposite-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribir el dataframe\n",
    "df_ucwpd.to_parquet('covid19/pd/usa_county_wise.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-candidate",
   "metadata": {},
   "source": [
    "### Cargar el archivo worldometer_data utilizando pandas y escribir archivo parquet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "after-thanks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de columnas: 16\n"
     ]
    }
   ],
   "source": [
    "# Cargar en un DtaFrame de pandas\n",
    "df_wdpd = pd.read_csv(\"covid19/worldometer_data.csv\", sep=',', quotechar='\"')\n",
    "\n",
    "# Contar número de columnas, Deben ser 16 columnas\n",
    "print(\"Número de columnas:\", df_wdpd.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "surprising-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corregir el nombre de las columnas\n",
    "df_wdpd.columns = ['CountryRegion', 'Continent', 'Population','TotalCases','NewCases','TotalDeaths','NewDeaths','TotalRecovered','NewRecovered','ActiveCases','SeriousCritical','TotCases1MPop','Deaths1MPop','TotalTests','Tests1MPop','Region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "commercial-glucose",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountryRegion       object\n",
      "Continent           object\n",
      "Population         float64\n",
      "TotalCases           int64\n",
      "NewCases           float64\n",
      "TotalDeaths        float64\n",
      "NewDeaths          float64\n",
      "TotalRecovered     float64\n",
      "NewRecovered       float64\n",
      "ActiveCases        float64\n",
      "SeriousCritical    float64\n",
      "TotCases1MPop      float64\n",
      "Deaths1MPop        float64\n",
      "TotalTests         float64\n",
      "Tests1MPop         float64\n",
      "Region              object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Validar que los tipos de datos sean los correctos\n",
    "print(df_wdpd.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "timely-carrier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             CountryRegion      Continent    Population  TotalCases  NewCases  \\\n",
      "0                      USA  North America  3.311981e+08     5032179       NaN   \n",
      "1                   Brazil  South America  2.127107e+08     2917562       NaN   \n",
      "2                    India           Asia  1.381345e+09     2025409       NaN   \n",
      "3                   Russia         Europe  1.459409e+08      871894       NaN   \n",
      "4             South Africa         Africa  5.938157e+07      538184       NaN   \n",
      "..                     ...            ...           ...         ...       ...   \n",
      "204             Montserrat  North America  4.992000e+03          13       NaN   \n",
      "205  Caribbean Netherlands  North America  2.624700e+04          13       NaN   \n",
      "206       Falkland Islands  South America  3.489000e+03          13       NaN   \n",
      "207           Vatican City         Europe  8.010000e+02          12       NaN   \n",
      "208         Western Sahara         Africa  5.986820e+05          10       NaN   \n",
      "\n",
      "     TotalDeaths  NewDeaths  TotalRecovered  NewRecovered  ActiveCases  \\\n",
      "0       162804.0        NaN       2576668.0           NaN    2292707.0   \n",
      "1        98644.0        NaN       2047660.0           NaN     771258.0   \n",
      "2        41638.0        NaN       1377384.0           NaN     606387.0   \n",
      "3        14606.0        NaN        676357.0           NaN     180931.0   \n",
      "4         9604.0        NaN        387316.0           NaN     141264.0   \n",
      "..           ...        ...             ...           ...          ...   \n",
      "204          1.0        NaN            10.0           NaN          2.0   \n",
      "205          NaN        NaN             7.0           NaN          6.0   \n",
      "206          NaN        NaN            13.0           NaN          0.0   \n",
      "207          NaN        NaN            12.0           NaN          0.0   \n",
      "208          1.0        NaN             8.0           NaN          1.0   \n",
      "\n",
      "     SeriousCritical  TotCases1MPop  Deaths1MPop  TotalTests  Tests1MPop  \\\n",
      "0            18296.0        15194.0        492.0  63139605.0    190640.0   \n",
      "1             8318.0        13716.0        464.0  13206188.0     62085.0   \n",
      "2             8944.0         1466.0         30.0  22149351.0     16035.0   \n",
      "3             2300.0         5974.0        100.0  29716907.0    203623.0   \n",
      "4              539.0         9063.0        162.0   3149807.0     53044.0   \n",
      "..               ...            ...          ...         ...         ...   \n",
      "204              NaN         2604.0        200.0        61.0     12220.0   \n",
      "205              NaN          495.0          NaN       424.0     16154.0   \n",
      "206              NaN         3726.0          NaN      1816.0    520493.0   \n",
      "207              NaN        14981.0          NaN         NaN         NaN   \n",
      "208              NaN           17.0          2.0         NaN         NaN   \n",
      "\n",
      "             Region  \n",
      "0          Americas  \n",
      "1          Americas  \n",
      "2    South-EastAsia  \n",
      "3            Europe  \n",
      "4            Africa  \n",
      "..              ...  \n",
      "204             NaN  \n",
      "205             NaN  \n",
      "206             NaN  \n",
      "207          Europe  \n",
      "208          Africa  \n",
      "\n",
      "[209 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "# Validar el Dataframe\n",
    "print(df_wdpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "complicated-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribir el dataframe\n",
    "df_wdpd.to_parquet('covid19/pd/worldometer_data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-maximum",
   "metadata": {},
   "source": [
    "### Crear Scripts para generar diagrama usando https://dbdiagram.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "conditional-montana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear funcion que escriba create table en el formato de https://dbdiagram.io/ para hacer el DER de los dataframes\n",
    "def generate_table(df,table_name):\n",
    "    # Obtener los tipos de datos de cada columna\n",
    "    column_types = {col: df[col].dtype for col in df.columns}\n",
    "    \n",
    "    # Construir la sentencia TABLE\n",
    "    create_table_sql = f\"TABLE {table_name} \"\n",
    "    create_table_sql += \"{\\n\"\n",
    "    for col, col_type in column_types.items():\n",
    "        if col_type == 'object':\n",
    "            col_type_sql = 'VARCHAR'\n",
    "        elif col_type == 'int64':\n",
    "            col_type_sql = 'INT'\n",
    "        elif col_type == 'float64':\n",
    "            col_type_sql = 'FLOAT'\n",
    "        elif col_type == 'datetime64[ns]':\n",
    "            col_type_sql = 'DATE'\n",
    "        else:\n",
    "            col_type_sql = 'VARCHAR(1000)'  # Tipo por defecto si no se reconoce el tipo de dato\n",
    "    \n",
    "        create_table_sql += f\"{col} {col_type_sql} \\n\"\n",
    "    \n",
    "    create_table_sql = create_table_sql.rstrip(' ')  \n",
    "    create_table_sql += \"}\"\n",
    "    \n",
    "    return create_table_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "local-clinton",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLE country_wise_latest {\n",
      "CountryRegion VARCHAR \n",
      "Confirmed INT \n",
      "Deaths INT \n",
      "Recovered INT \n",
      "Active INT \n",
      "NewCases INT \n",
      "NewDeaths INT \n",
      "NewRecovered INT \n",
      "Deaths100Cases FLOAT \n",
      "Recovered100Cases FLOAT \n",
      "Deaths100Recovered FLOAT \n",
      "ConfirmedLastWeek INT \n",
      "1WeekChange INT \n",
      "1WeekIncrease FLOAT \n",
      "WhoRegion VARCHAR \n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Crear Script para la tabla country_wise_latest\n",
    "print(generate_table(df_cwlpd,'country_wise_latest'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "advised-emperor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLE covid_19_clean_complete {\n",
      "ProvinceState VARCHAR \n",
      "CountryRegion VARCHAR \n",
      "Lat FLOAT \n",
      "Long FLOAT \n",
      "Date DATE \n",
      "Confirmed INT \n",
      "Deaths INT \n",
      "Recovered INT \n",
      "Active INT \n",
      "WhoRegion VARCHAR \n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Crear Script para la tabla covid_19_clean_complete\n",
    "print(generate_table(df_cccpd,'covid_19_clean_complete'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fatty-father",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLE day_wise {\n",
      "Date DATE \n",
      "Confirmed INT \n",
      "Deaths INT \n",
      "Recovered INT \n",
      "Active INT \n",
      "NewCases INT \n",
      "NewDeaths INT \n",
      "NewRecovered INT \n",
      "Deaths100Cases FLOAT \n",
      "Recovered100Cases FLOAT \n",
      "Deaths100Recovered FLOAT \n",
      "NoOfContries INT \n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Crear Script para la tabla day_wise\n",
    "print(generate_table(df_dwpd,'day_wise'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fallen-cambridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLE full_grouped {\n",
      "Date DATE \n",
      "CountryRegion VARCHAR \n",
      "Confirmed INT \n",
      "Deaths INT \n",
      "Recovered INT \n",
      "Active INT \n",
      "NewCases INT \n",
      "NewDeaths INT \n",
      "NewRecovered INT \n",
      "WhoRegion VARCHAR \n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Crear Script para la tabla full_grouped\n",
    "print(generate_table(df_fgpd,'full_grouped'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "black-modern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLE usa_county_wise {\n",
      "UID INT \n",
      "ISO2 VARCHAR \n",
      "ISO3 VARCHAR \n",
      "Code3 INT \n",
      "FIPS FLOAT \n",
      "Admin2 VARCHAR \n",
      "ProvinceState VARCHAR \n",
      "CountryRegion VARCHAR \n",
      "Lat FLOAT \n",
      "Long FLOAT \n",
      "CombinedKey VARCHAR \n",
      "Date DATE \n",
      "Confirmed INT \n",
      "Deaths INT \n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Crear Script para la tabla usa_county_wise\n",
    "print(generate_table(df_ucwpd,'usa_county_wise'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "compound-coral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLE worldometer_data {\n",
      "CountryRegion VARCHAR \n",
      "Continent VARCHAR \n",
      "Population FLOAT \n",
      "TotalCases INT \n",
      "NewCases FLOAT \n",
      "TotalDeaths FLOAT \n",
      "NewDeaths FLOAT \n",
      "TotalRecovered FLOAT \n",
      "NewRecovered FLOAT \n",
      "ActiveCases FLOAT \n",
      "SeriousCritical FLOAT \n",
      "TotCases1MPop FLOAT \n",
      "Deaths1MPop FLOAT \n",
      "TotalTests FLOAT \n",
      "Tests1MPop FLOAT \n",
      "Region VARCHAR \n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Crear Script para la tabla worldometer_data\n",
    "print(generate_table(df_wdpd,'worldometer_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-sperm",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
